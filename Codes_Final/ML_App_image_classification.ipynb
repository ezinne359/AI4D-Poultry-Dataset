{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ML_App_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKRaYHABpob5"
      },
      "source": [
        "## Modeling a Machine Learning App for Poultry Diseases Diagnostics\n",
        "* The dataset of poultry [fecal images](http://doi.org/10.5281/zenodo.4628934) is used for training\n",
        "\n",
        "* Image classification task with [TensorFlow Lite Model Maker](https://www.tensorflow.org/lite/tutorials/model_maker_image_classification)\n",
        "* Model Architecture: MobileNet\n",
        "* The end-to-end model will be deployed on Android mobile device for detection of Salmonella and Coccidiosis diseases and the Healthy poultry\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "We first need to install several required packages, including Model Maker package that in GitHub [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cv3K3oaksJv"
      },
      "source": [
        "!pip install tflite-model-maker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx1HGRoFQ54j"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import configs\n",
        "from tflite_model_maker import ExportFormat\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker import ImageClassifierDataLoader\n",
        "from tflite_model_maker import model_spec\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiZZ5DHXotaW"
      },
      "source": [
        "### Load Dataset\n",
        "* Get the data path for the poultry diseases dataset\n",
        "* We will use 500 poultry fecal images for each class \n",
        "* The model is trained for three classes of:\n",
        "   - Salmonela disease (`salmo`)\n",
        "   - Coccidiosis disease (`cocci`) and\n",
        "   - Normal (`healthy`)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ygTK5qFejb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206cc7e3-a9db-405a-85d8-3e1740bfed09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTbJflTefj8J"
      },
      "source": [
        "image_path = '/content/gdrive/MyDrive/poultryFecal_images'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usencrcyibjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46eb1b81-8af1-47b0-e679-1e47ccb48028"
      },
      "source": [
        "os.listdir(image_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['healthy', 'salmo', 'cocci']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VDriAdsowu"
      },
      "source": [
        "### Training on MOBILENET V1 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "### Step 1: Load Input Data Specific to an On-device ML App\n",
        "\n",
        "* The poultry dataset contains 1500 fecal images belonging to 3 classes. \n",
        "* Train and test split is 0.9/0.1\n",
        "\n",
        "* The dataset has the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>poultryFecal_images</b>\n",
        "|__ <b>cocci</b>\n",
        "    |______ cocci.0.jpg\n",
        "    |______ cocci.1.jpg\n",
        "    |______ ...\n",
        "|__ <b>healthy</b>\n",
        "    |______ healthy.0.jpg\n",
        "    |______ healthy.1.jpg\n",
        "    |______ ...\n",
        "|__ <b>salmo</b>\n",
        "    |______ salmo.0.jpg\n",
        "    |______ salmo.1.jpg\n",
        "    |______ ...\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANoNS_gtdH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92178d36-1553-4af4-f9df-01991fc9514d"
      },
      "source": [
        "data = ImageClassifierDataLoader.from_folder(image_path)\n",
        "train_data, test_data = data.split(0.9)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 1500, num_label: 3, labels: cocci, healthy, salmo.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9IWyIztuRF"
      },
      "source": [
        "### Step 2. Customize and Train the TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRXMZbrwtyRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb21da68-f841-44f9-be29-e05ec6170dc4"
      },
      "source": [
        "model = image_classifier.create(train_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hub_keras_layer_v1v2 (HubKer (None, 1280)              3413024   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 3843      \n",
            "=================================================================\n",
            "Total params: 3,416,867\n",
            "Trainable params: 3,843\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "42/42 [==============================] - 378s 9s/step - loss: 0.8247 - accuracy: 0.6755\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 86s 2s/step - loss: 0.4455 - accuracy: 0.9361\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 83s 2s/step - loss: 0.4120 - accuracy: 0.9573\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 84s 2s/step - loss: 0.4045 - accuracy: 0.9587\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 82s 2s/step - loss: 0.3900 - accuracy: 0.9680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU2fDr-t2Ya"
      },
      "source": [
        "### Step 3. Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQr02VxJt6Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6f757f-9f61-4f57-d3c8-5af58b4e5ba2"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 110s 6s/step - loss: 0.3885 - accuracy: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVZw9zU8t84y"
      },
      "source": [
        "### Step 4.  Export to TensorFlow Lite model.\n",
        "\n",
        "Here, we export TensorFlow Lite model with [metadata](https://www.tensorflow.org/lite/convert/metadata) which provides a standard for model descriptions. The label file is embedded in metadata.\n",
        "\n",
        "You could download it in the left sidebar same as the uploading part for your own use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-eIzfluCoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40bdf50d-494b-4a4f-ab11-6224e8bd720d"
      },
      "source": [
        "model.export(export_dir='.')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmlkz2k66/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmlkz2k66/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp5ajstu27/labels.txt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp5ajstu27/labels.txt.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0zH-m4A92PT"
      },
      "source": [
        "### Training on MOBILENET V2\n",
        "\n",
        "For comparison with MobileNet V1 above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkHxSXnbFoaD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fa6100-f597-409f-9450-158bf76364a1"
      },
      "source": [
        "model = image_classifier.create(train_data, model_spec=model_spec.mobilenet_v2_spec, epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hub_keras_layer_v1v2_1 (HubK (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 3843      \n",
            "=================================================================\n",
            "Total params: 2,261,827\n",
            "Trainable params: 3,843\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "42/42 [==============================] - 87s 2s/step - loss: 0.9542 - accuracy: 0.6528\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 82s 2s/step - loss: 0.4441 - accuracy: 0.9638\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 83s 2s/step - loss: 0.4211 - accuracy: 0.9559\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 84s 2s/step - loss: 0.4030 - accuracy: 0.9743\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 82s 2s/step - loss: 0.3882 - accuracy: 0.9697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB2Go3HW8X7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8157b05d-8766-41c8-9ed8-d6b82e2e9b28"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 25s 2s/step - loss: 0.3883 - accuracy: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyju1qc_v-wy"
      },
      "source": [
        "### Step 5. Deployment.\n",
        "* MobileNet V2 model has higher accuracy on training but same accuracy on testing compared to MobileNet V1.\n",
        "\n",
        "* Deployment used MobileNet V1 model\n",
        "\n",
        "* The TensorFlow Lite model file (`model.tflite`) was deployed on Android using the in on-device application [image classification](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification) reference app."
      ]
    }
  ]
}